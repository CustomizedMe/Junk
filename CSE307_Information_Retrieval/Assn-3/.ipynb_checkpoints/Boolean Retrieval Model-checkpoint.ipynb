{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/parzival/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/parzival/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/parzival/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "directory = \"../collection/20_newsgroup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing :\n",
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(text, lemmatizer=WordNetLemmatizer()):\n",
    "    words = [w.lower() for w in word_tokenize(text)]\n",
    "    tokens = []\n",
    "    for token in words:\n",
    "        tokens.extend(re.split('[^a-zA-Z]', token))\n",
    "    token_list = [lemmatizer.lemmatize(token) for token in tokens if not token in stopwords.words('english')] \n",
    "    return list(filter(lambda token: len(token), token_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graphic']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_line(\"graphic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_doc(doc_path):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    with open(doc_path, encoding=\"utf8\", errors='ignore') as f:\n",
    "\n",
    "        tokens = []\n",
    "        endOfDoc=0\n",
    "        isHeader=1\n",
    "        \n",
    "        data = list(filter( lambda line: line!=\"\\n\",f.readlines()))\n",
    "        for line in data:\n",
    "            text = line\n",
    "            \n",
    "#             if isHeader==1:\n",
    "#                 parts = line.split(\": \")\n",
    "#                 try:\n",
    "#                     text = parts[1]\n",
    "#                 except IndexError as err:\n",
    "#                     print(line)\n",
    "#                     raise IndexError(err)\n",
    "#                 if str(parts[0])==\"Lines\":\n",
    "#                     isHeader=0\n",
    "            \n",
    "            tokens.extend(preprocess_line(text,lemmatizer))\n",
    "            \n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Posting List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_posting(newsgroup=\"comp.graphics\"):\n",
    "    \n",
    "    doc_id = -1\n",
    "    doc_name = {}\n",
    "    post_list = {}\n",
    "    doc_len = {}\n",
    "    idf = {}\n",
    "    tf = {}\n",
    "    \n",
    "    working_dir = directory+\"/\"+newsgroup\n",
    "    for file in os.listdir(working_dir):\n",
    "        doc_id += 1\n",
    "        tf[doc_id] = {}\n",
    "        doc_len[doc_id] = 0\n",
    "        \n",
    "        filename = os.fsdecode(file)\n",
    "        doc_name[doc_id] = filename\n",
    "        \n",
    "        file_path = os.path.join(working_dir,file)\n",
    "        \n",
    "        tokens = preprocess_doc(file_path)\n",
    "        \n",
    "        doc_len[doc_id] = len(tokens)\n",
    "        \n",
    "        for token in tokens:    \n",
    "            if post_list.get(token) == None:\n",
    "                post_list[token] = [doc_id]\n",
    "                tf[doc_id][token] = 0\n",
    "                idf[token] = 1\n",
    "            elif tf[doc_id].get(token) == None:\n",
    "                post_list[token].append(doc_id)\n",
    "                tf[doc_id][token] = 0\n",
    "                idf[token] += 1\n",
    "            tf[doc_id][token] += 1\n",
    "            \n",
    "        for j in tf[doc_id].keys():\n",
    "            tf[doc_id][j] /= doc_len[doc_id]\n",
    "            \n",
    "    for i in idf.keys():\n",
    "        idf[i]=math.log10((doc_id+1)/idf[i])\n",
    "    \n",
    "    return {\"doc_names\": doc_name, \"post_list\": post_list, \"doc_lens\": doc_len, \"tf\":tf, \"idf\":idf}            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "postings = create_posting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " class BooleanModel:\n",
    "    def __init__(self,posting_list):\n",
    "        self.postings = posting_list\n",
    "    \n",
    "    def __and__(self,token_1,token_2):\n",
    "        return list(set(token_1) & set(token_2))\n",
    "            \n",
    "    \n",
    "    def __or__(self,token_1,token_2):\n",
    "        return list(set(token_1).union(set(token_2)))\n",
    "    \n",
    "    def __not__(self,token):\n",
    "        doc_list = set(list(self.postings[\"doc_names\"].keys()))\n",
    "        print(len(doc_list))\n",
    "        print(len(token))\n",
    "        return list(doc_list.difference(set(token)))\n",
    "    \n",
    "    def evaluate(self,query):\n",
    "    \n",
    "        ops = ('and', 'or', 'not')\n",
    "        stk = []\n",
    "        result = []\n",
    "    \n",
    "        postfix = self.__parse__(query)\n",
    "        print(postfix)\n",
    "    \n",
    "        for op in postfix:\n",
    "            if op not in ops:\n",
    "                stk.append(self.postings[\"post_list\"][op])\n",
    "                continue\n",
    "            \n",
    "            if op == \"not\":\n",
    "                word = stk.pop()\n",
    "                stk.append(self.__not__(word))\n",
    "            elif op == \"and\":\n",
    "                word1 = stk.pop()\n",
    "                word2 = stk.pop()\n",
    "                stk.append(self.__and__(word1,word2))\n",
    "            else:\n",
    "                word1 = stk.pop()\n",
    "                word2 = stk.pop()\n",
    "                stk.append(self.__or__(word1,word2))\n",
    "                \n",
    "        return stk[0]\n",
    "            \n",
    "    \n",
    "    def __parse__(self,query):\n",
    "        words = query.split()\n",
    "        ops = ('and', 'or', 'not')\n",
    "        stk = []\n",
    "        tokenized_string = \"\"\n",
    "        postfix = []\n",
    "        \n",
    "        for word in words:\n",
    "            if word not in ops:\n",
    "                temp = preprocess_line(word)\n",
    "                for t in temp:\n",
    "                    tokenized_string += t + \" and \"\n",
    "                tokenized_string = tokenized_string[:-4]    \n",
    "            else:\n",
    "                tokenized_string += word + \" \"\n",
    "        \n",
    "        tokens = tokenized_string.split()\n",
    "        \n",
    "        for word in tokens:\n",
    "            if word not in ops:              \n",
    "                postfix.append(word)\n",
    "                continue\n",
    "            if word == \"not\":\n",
    "                stk.append(\"not\")\n",
    "            else:\n",
    "                if len(stk)==0 or stk[-1] != \"not\":\n",
    "                    stk.append(word)\n",
    "                else:\n",
    "                    stk.reverse()\n",
    "                    for t in stk:\n",
    "                        postfix.append(t)\n",
    "                    stk = []\n",
    "                    stk.append(word)\n",
    "                    \n",
    "        if len(stk) > 0:\n",
    "            stk.reverse()\n",
    "            for t in stk:\n",
    "                postfix.append(t)\n",
    "                \n",
    "        return postfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = BooleanModel(postings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bm.evluate(\"computer and graphics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['computer', 'graphic', 'good', 'not', 'and', 'and']\n",
      "1000\n",
      "148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 4,\n",
       " 516,\n",
       " 6,\n",
       " 8,\n",
       " 520,\n",
       " 522,\n",
       " 17,\n",
       " 20,\n",
       " 539,\n",
       " 540,\n",
       " 29,\n",
       " 543,\n",
       " 39,\n",
       " 551,\n",
       " 552,\n",
       " 554,\n",
       " 556,\n",
       " 565,\n",
       " 57,\n",
       " 62,\n",
       " 574,\n",
       " 576,\n",
       " 577,\n",
       " 67,\n",
       " 580,\n",
       " 72,\n",
       " 74,\n",
       " 79,\n",
       " 80,\n",
       " 593,\n",
       " 596,\n",
       " 602,\n",
       " 93,\n",
       " 96,\n",
       " 609,\n",
       " 102,\n",
       " 104,\n",
       " 616,\n",
       " 618,\n",
       " 620,\n",
       " 112,\n",
       " 117,\n",
       " 630,\n",
       " 122,\n",
       " 123,\n",
       " 127,\n",
       " 128,\n",
       " 642,\n",
       " 131,\n",
       " 132,\n",
       " 134,\n",
       " 646,\n",
       " 137,\n",
       " 649,\n",
       " 650,\n",
       " 140,\n",
       " 145,\n",
       " 148,\n",
       " 157,\n",
       " 670,\n",
       " 671,\n",
       " 160,\n",
       " 161,\n",
       " 163,\n",
       " 678,\n",
       " 679,\n",
       " 681,\n",
       " 174,\n",
       " 690,\n",
       " 696,\n",
       " 186,\n",
       " 188,\n",
       " 703,\n",
       " 705,\n",
       " 707,\n",
       " 198,\n",
       " 201,\n",
       " 202,\n",
       " 713,\n",
       " 714,\n",
       " 208,\n",
       " 731,\n",
       " 732,\n",
       " 222,\n",
       " 735,\n",
       " 741,\n",
       " 230,\n",
       " 742,\n",
       " 747,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 757,\n",
       " 758,\n",
       " 760,\n",
       " 763,\n",
       " 767,\n",
       " 256,\n",
       " 771,\n",
       " 774,\n",
       " 781,\n",
       " 271,\n",
       " 274,\n",
       " 277,\n",
       " 279,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 798,\n",
       " 292,\n",
       " 805,\n",
       " 807,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 816,\n",
       " 306,\n",
       " 309,\n",
       " 824,\n",
       " 825,\n",
       " 315,\n",
       " 316,\n",
       " 834,\n",
       " 838,\n",
       " 329,\n",
       " 335,\n",
       " 336,\n",
       " 340,\n",
       " 343,\n",
       " 856,\n",
       " 354,\n",
       " 866,\n",
       " 356,\n",
       " 867,\n",
       " 358,\n",
       " 868,\n",
       " 874,\n",
       " 365,\n",
       " 366,\n",
       " 878,\n",
       " 881,\n",
       " 372,\n",
       " 374,\n",
       " 887,\n",
       " 889,\n",
       " 891,\n",
       " 380,\n",
       " 382,\n",
       " 383,\n",
       " 895,\n",
       " 900,\n",
       " 390,\n",
       " 902,\n",
       " 394,\n",
       " 907,\n",
       " 397,\n",
       " 915,\n",
       " 405,\n",
       " 919,\n",
       " 922,\n",
       " 411,\n",
       " 929,\n",
       " 931,\n",
       " 933,\n",
       " 937,\n",
       " 938,\n",
       " 427,\n",
       " 429,\n",
       " 432,\n",
       " 945,\n",
       " 947,\n",
       " 949,\n",
       " 440,\n",
       " 442,\n",
       " 445,\n",
       " 960,\n",
       " 451,\n",
       " 964,\n",
       " 966,\n",
       " 455,\n",
       " 968,\n",
       " 969,\n",
       " 971,\n",
       " 974,\n",
       " 975,\n",
       " 465,\n",
       " 977,\n",
       " 989,\n",
       " 991,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.evaluate(\"computer and graphics and not good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['computer', 'graph', 'or']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 17,\n",
       " 20,\n",
       " 26,\n",
       " 29,\n",
       " 39,\n",
       " 42,\n",
       " 52,\n",
       " 56,\n",
       " 57,\n",
       " 60,\n",
       " 62,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 69,\n",
       " 72,\n",
       " 74,\n",
       " 79,\n",
       " 80,\n",
       " 93,\n",
       " 96,\n",
       " 99,\n",
       " 102,\n",
       " 104,\n",
       " 112,\n",
       " 117,\n",
       " 122,\n",
       " 123,\n",
       " 127,\n",
       " 128,\n",
       " 131,\n",
       " 132,\n",
       " 134,\n",
       " 137,\n",
       " 140,\n",
       " 145,\n",
       " 148,\n",
       " 153,\n",
       " 157,\n",
       " 160,\n",
       " 161,\n",
       " 163,\n",
       " 169,\n",
       " 174,\n",
       " 177,\n",
       " 180,\n",
       " 186,\n",
       " 188,\n",
       " 197,\n",
       " 198,\n",
       " 201,\n",
       " 202,\n",
       " 208,\n",
       " 222,\n",
       " 230,\n",
       " 233,\n",
       " 235,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 251,\n",
       " 254,\n",
       " 256,\n",
       " 257,\n",
       " 271,\n",
       " 274,\n",
       " 277,\n",
       " 279,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 292,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 306,\n",
       " 309,\n",
       " 315,\n",
       " 316,\n",
       " 329,\n",
       " 330,\n",
       " 335,\n",
       " 336,\n",
       " 340,\n",
       " 342,\n",
       " 343,\n",
       " 354,\n",
       " 356,\n",
       " 358,\n",
       " 365,\n",
       " 366,\n",
       " 372,\n",
       " 374,\n",
       " 380,\n",
       " 382,\n",
       " 383,\n",
       " 390,\n",
       " 393,\n",
       " 394,\n",
       " 397,\n",
       " 398,\n",
       " 403,\n",
       " 405,\n",
       " 407,\n",
       " 410,\n",
       " 411,\n",
       " 420,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 432,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 444,\n",
       " 445,\n",
       " 451,\n",
       " 455,\n",
       " 465,\n",
       " 481,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 514,\n",
       " 516,\n",
       " 520,\n",
       " 522,\n",
       " 530,\n",
       " 539,\n",
       " 540,\n",
       " 543,\n",
       " 544,\n",
       " 551,\n",
       " 552,\n",
       " 554,\n",
       " 556,\n",
       " 565,\n",
       " 574,\n",
       " 576,\n",
       " 577,\n",
       " 580,\n",
       " 589,\n",
       " 593,\n",
       " 596,\n",
       " 597,\n",
       " 599,\n",
       " 602,\n",
       " 606,\n",
       " 609,\n",
       " 613,\n",
       " 616,\n",
       " 618,\n",
       " 620,\n",
       " 628,\n",
       " 630,\n",
       " 632,\n",
       " 642,\n",
       " 646,\n",
       " 649,\n",
       " 650,\n",
       " 670,\n",
       " 671,\n",
       " 676,\n",
       " 678,\n",
       " 679,\n",
       " 681,\n",
       " 690,\n",
       " 696,\n",
       " 703,\n",
       " 705,\n",
       " 707,\n",
       " 713,\n",
       " 714,\n",
       " 716,\n",
       " 720,\n",
       " 726,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 735,\n",
       " 741,\n",
       " 742,\n",
       " 747,\n",
       " 753,\n",
       " 757,\n",
       " 758,\n",
       " 760,\n",
       " 763,\n",
       " 767,\n",
       " 771,\n",
       " 773,\n",
       " 774,\n",
       " 781,\n",
       " 797,\n",
       " 798,\n",
       " 805,\n",
       " 807,\n",
       " 809,\n",
       " 816,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 834,\n",
       " 838,\n",
       " 856,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 874,\n",
       " 878,\n",
       " 881,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 891,\n",
       " 895,\n",
       " 898,\n",
       " 900,\n",
       " 902,\n",
       " 907,\n",
       " 915,\n",
       " 919,\n",
       " 922,\n",
       " 927,\n",
       " 929,\n",
       " 931,\n",
       " 933,\n",
       " 937,\n",
       " 938,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 949,\n",
       " 960,\n",
       " 964,\n",
       " 966,\n",
       " 968,\n",
       " 969,\n",
       " 971,\n",
       " 974,\n",
       " 975,\n",
       " 977,\n",
       " 980,\n",
       " 989,\n",
       " 991]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.evaluate(\"computer or graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['graph']\n"
     ]
    }
   ],
   "source": [
    "lg = bm.evaluate(\"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['computer', 'not']\n",
      "1000\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "lc = bm.evaluate(\"not computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 750\n"
     ]
    }
   ],
   "source": [
    "print(len(lg), len(lc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{233, 254, 256, 257, 279, 301, 407, 597, 696, 720}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(lg) & set(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 17,\n",
       " 20,\n",
       " 26,\n",
       " 29,\n",
       " 39,\n",
       " 42,\n",
       " 52,\n",
       " 56,\n",
       " 57,\n",
       " 60,\n",
       " 62,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 69,\n",
       " 72,\n",
       " 74,\n",
       " 79,\n",
       " 80,\n",
       " 93,\n",
       " 96,\n",
       " 99,\n",
       " 102,\n",
       " 104,\n",
       " 112,\n",
       " 117,\n",
       " 122,\n",
       " 123,\n",
       " 127,\n",
       " 128,\n",
       " 131,\n",
       " 132,\n",
       " 134,\n",
       " 137,\n",
       " 140,\n",
       " 145,\n",
       " 148,\n",
       " 153,\n",
       " 157,\n",
       " 160,\n",
       " 161,\n",
       " 163,\n",
       " 169,\n",
       " 174,\n",
       " 177,\n",
       " 180,\n",
       " 186,\n",
       " 188,\n",
       " 197,\n",
       " 198,\n",
       " 201,\n",
       " 202,\n",
       " 208,\n",
       " 222,\n",
       " 230,\n",
       " 233,\n",
       " 235,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 251,\n",
       " 254,\n",
       " 256,\n",
       " 257,\n",
       " 271,\n",
       " 274,\n",
       " 277,\n",
       " 279,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 292,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 306,\n",
       " 309,\n",
       " 315,\n",
       " 316,\n",
       " 329,\n",
       " 330,\n",
       " 335,\n",
       " 336,\n",
       " 340,\n",
       " 342,\n",
       " 343,\n",
       " 354,\n",
       " 356,\n",
       " 358,\n",
       " 365,\n",
       " 366,\n",
       " 372,\n",
       " 374,\n",
       " 380,\n",
       " 382,\n",
       " 383,\n",
       " 390,\n",
       " 393,\n",
       " 394,\n",
       " 397,\n",
       " 398,\n",
       " 403,\n",
       " 405,\n",
       " 407,\n",
       " 410,\n",
       " 411,\n",
       " 420,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 432,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 444,\n",
       " 445,\n",
       " 451,\n",
       " 455,\n",
       " 465,\n",
       " 481,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 514,\n",
       " 516,\n",
       " 520,\n",
       " 522,\n",
       " 530,\n",
       " 539,\n",
       " 540,\n",
       " 543,\n",
       " 544,\n",
       " 551,\n",
       " 552,\n",
       " 554,\n",
       " 556,\n",
       " 565,\n",
       " 574,\n",
       " 576,\n",
       " 577,\n",
       " 580,\n",
       " 589,\n",
       " 593,\n",
       " 596,\n",
       " 597,\n",
       " 599,\n",
       " 602,\n",
       " 606,\n",
       " 609,\n",
       " 613,\n",
       " 616,\n",
       " 618,\n",
       " 620,\n",
       " 628,\n",
       " 630,\n",
       " 632,\n",
       " 642,\n",
       " 646,\n",
       " 649,\n",
       " 650,\n",
       " 670,\n",
       " 671,\n",
       " 676,\n",
       " 678,\n",
       " 679,\n",
       " 681,\n",
       " 690,\n",
       " 696,\n",
       " 703,\n",
       " 705,\n",
       " 707,\n",
       " 713,\n",
       " 714,\n",
       " 716,\n",
       " 720,\n",
       " 726,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 735,\n",
       " 741,\n",
       " 742,\n",
       " 747,\n",
       " 753,\n",
       " 757,\n",
       " 758,\n",
       " 760,\n",
       " 763,\n",
       " 767,\n",
       " 771,\n",
       " 773,\n",
       " 774,\n",
       " 781,\n",
       " 797,\n",
       " 798,\n",
       " 805,\n",
       " 807,\n",
       " 809,\n",
       " 816,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 834,\n",
       " 838,\n",
       " 856,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 874,\n",
       " 878,\n",
       " 881,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 891,\n",
       " 895,\n",
       " 898,\n",
       " 900,\n",
       " 902,\n",
       " 907,\n",
       " 915,\n",
       " 919,\n",
       " 922,\n",
       " 927,\n",
       " 929,\n",
       " 931,\n",
       " 933,\n",
       " 937,\n",
       " 938,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 949,\n",
       " 960,\n",
       " 964,\n",
       " 966,\n",
       " 968,\n",
       " 969,\n",
       " 971,\n",
       " 974,\n",
       " 975,\n",
       " 977,\n",
       " 980,\n",
       " 989,\n",
       " 991}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(lg) | set(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
