Loading data...
# of sentences = 21086
Splitting data at 70%:30%...
Fitting the model for MODE (0) ...
Predicting labels...
F1 score:  0.9743432092164278
              precision    recall  f1-score   support

       B-BLK      0.996     0.996     0.996      6658
       I-BLK      0.906     0.892     0.899        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.988     0.940     0.963        84
     B-FRAGP      0.708     0.605     0.652       124
     I-FRAGP      0.625     0.294     0.400        17
       B-JJP      0.964     0.913     0.938      3158
       I-JJP      0.810     0.691     0.746       278
      B-NEGP      0.825     0.925     0.872       107
      I-NEGP      0.857     0.960     0.906        25
        B-NP      0.964     0.971     0.968     40861
        I-NP      0.973     0.973     0.973     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.973     0.766     0.857        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.882     0.877     0.879       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.976     0.980     0.978       741
       I-RBP      0.974     0.963     0.968       191
       B-VGF      0.990     0.993     0.991      9911
       I-VGF      0.991     0.995     0.993      9273
      B-VGNF      0.948     0.966     0.957      1578
      I-VGNF      0.960     0.953     0.957       658
      B-VGNN      0.992     0.967     0.979      2511
      I-VGNN      0.992     0.990     0.991      3084

   micro avg      0.975     0.975     0.975    131574
   macro avg      0.741     0.701     0.715    131574
weighted avg      0.974     0.975     0.974    131574

Sentence Labelling Error :
Number of sentences wrongly labelled : 147
Fitting the model for MODE (1) ...
Predicting labels...
F1 score:  0.9742207922785058
              precision    recall  f1-score   support

       B-BLK      0.996     0.996     0.996      6658
       I-BLK      0.894     0.908     0.901        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.988     0.940     0.963        84
     B-FRAGP      0.693     0.637     0.664       124
     I-FRAGP      0.500     0.353     0.414        17
       B-JJP      0.962     0.911     0.936      3158
       I-JJP      0.812     0.655     0.725       278
      B-NEGP      0.825     0.925     0.872       107
      I-NEGP      0.857     0.960     0.906        25
        B-NP      0.963     0.972     0.967     40861
        I-NP      0.974     0.972     0.973     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.973     0.777     0.864        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.878     0.890     0.884       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.975     0.981     0.978       741
       I-RBP      0.959     0.974     0.966       191
       B-VGF      0.991     0.993     0.992      9911
       I-VGF      0.992     0.994     0.993      9273
      B-VGNF      0.953     0.966     0.959      1578
      I-VGNF      0.962     0.951     0.956       658
      B-VGNN      0.987     0.970     0.979      2511
      I-VGNN      0.992     0.990     0.991      3084

   micro avg      0.974     0.974     0.974    131574
   macro avg      0.736     0.704     0.715    131574
weighted avg      0.974     0.974     0.974    131574

Sentence Labelling Error :
Number of sentences wrongly labelled : 153
Fitting the model for MODE (2) ...
Predicting labels...
F1 score:  0.9747063690773266
              precision    recall  f1-score   support

       B-BLK      0.996     0.996     0.996      6658
       I-BLK      0.892     0.892     0.892        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.975     0.940     0.958        84
     B-FRAGP      0.705     0.597     0.646       124
     I-FRAGP      0.538     0.412     0.467        17
       B-JJP      0.966     0.911     0.938      3158
       I-JJP      0.831     0.673     0.744       278
      B-NEGP      0.826     0.935     0.877       107
      I-NEGP      0.828     0.960     0.889        25
        B-NP      0.964     0.971     0.968     40861
        I-NP      0.973     0.973     0.973     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.973     0.777     0.864        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.883     0.883     0.883       154
 I-NULL__VGF      0.957     0.407     0.571        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.972     0.981     0.976       741
       I-RBP      0.959     0.974     0.966       191
       B-VGF      0.993     0.993     0.993      9911
       I-VGF      0.994     0.994     0.994      9273
      B-VGNF      0.952     0.968     0.960      1578
      I-VGNF      0.959     0.960     0.960       658
      B-VGNN      0.988     0.978     0.983      2511
      I-VGNN      0.990     0.994     0.992      3084

   micro avg      0.975     0.975     0.975    131574
   macro avg      0.737     0.705     0.716    131574
weighted avg      0.975     0.975     0.975    131574

Sentence Labelling Error :
Number of sentences wrongly labelled : 151
Fitting the model for MODE (3) ...
Predicting labels...
F1 score:  0.9744858570526507
              precision    recall  f1-score   support

       B-BLK      0.996     0.996     0.996      6658
       I-BLK      0.879     0.892     0.885        65
       B-CCP      0.999     0.995     0.997      4789
       I-CCP      0.987     0.929     0.957        84
     B-FRAGP      0.718     0.597     0.652       124
     I-FRAGP      0.556     0.294     0.385        17
       B-JJP      0.967     0.909     0.937      3158
       I-JJP      0.824     0.673     0.741       278
      B-NEGP      0.826     0.935     0.877       107
      I-NEGP      0.857     0.960     0.906        25
        B-NP      0.964     0.971     0.967     40861
        I-NP      0.973     0.974     0.973     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.974     0.787     0.871        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.884     0.890     0.887       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.976     0.982     0.979       741
       I-RBP      0.959     0.974     0.966       191
       B-VGF      0.992     0.993     0.992      9911
       I-VGF      0.994     0.993     0.994      9273
      B-VGNF      0.952     0.966     0.959      1578
      I-VGNF      0.952     0.962     0.957       658
      B-VGNN      0.988     0.976     0.982      2511
      I-VGNN      0.989     0.994     0.991      3084

   micro avg      0.975     0.975     0.975    131574
   macro avg      0.738     0.702     0.714    131574
weighted avg      0.975     0.975     0.974    131574

Sentence Labelling Error :
Number of sentences wrongly labelled : 151
Fitting the model for MODE (8) ...
Predicting labels...
F1 score:  0.9753641183595508
              precision    recall  f1-score   support

       B-BLK      0.996     0.995     0.996      6658
       I-BLK      0.894     0.908     0.901        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.988     0.940     0.963        84
     B-FRAGP      0.682     0.589     0.632       124
     I-FRAGP      0.600     0.353     0.444        17
       B-JJP      0.969     0.911     0.939      3158
       I-JJP      0.860     0.687     0.764       278
      B-NEGP      0.825     0.925     0.872       107
      I-NEGP      0.857     0.960     0.906        25
        B-NP      0.964     0.972     0.968     40861
        I-NP      0.974     0.974     0.974     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.974     0.787     0.871        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.874     0.857     0.866       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.973     0.981     0.977       741
       I-RBP      0.964     0.974     0.969       191
       B-VGF      0.994     0.993     0.993      9911
       I-VGF      0.995     0.995     0.995      9273
      B-VGNF      0.964     0.969     0.966      1578
      I-VGNF      0.966     0.953     0.959       658
      B-VGNN      0.994     0.994     0.994      2511
      I-VGNN      0.991     0.997     0.994      3084

   micro avg      0.976     0.976     0.976    131574
   macro avg      0.741     0.704     0.717    131574
weighted avg      0.975     0.976     0.975    131574

Sentence Labelling Error :
Number of sentences wrongly labelled : 150
Fitting the model for MODE (11) ...
Predicting labels...
F1 score:  0.9754141902642991
              precision    recall  f1-score   support

       B-BLK      0.996     0.995     0.996      6658
       I-BLK      0.879     0.892     0.885        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.975     0.940     0.958        84
     B-FRAGP      0.689     0.677     0.683       124
     I-FRAGP      0.500     0.471     0.485        17
       B-JJP      0.965     0.910     0.937      3158
       I-JJP      0.856     0.683     0.760       278
      B-NEGP      0.826     0.935     0.877       107
      I-NEGP      0.857     0.960     0.906        25
        B-NP      0.964     0.972     0.968     40861
        I-NP      0.974     0.973     0.974     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.974     0.787     0.871        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.872     0.883     0.877       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.976     0.980     0.978       741
       I-RBP      0.954     0.974     0.964       191
       B-VGF      0.994     0.993     0.993      9911
       I-VGF      0.995     0.994     0.994      9273
      B-VGNF      0.970     0.971     0.971      1578
      I-VGNF      0.962     0.964     0.963       658
      B-VGNN      0.992     0.996     0.994      2511
      I-VGNN      0.994     0.997     0.995      3084

   micro avg      0.976     0.976     0.976    131574
   macro avg      0.737     0.712     0.720    131574
weighted avg      0.975     0.976     0.975    131574

Sentence Labelling Error :
Number of sentences wrongly labelled : 141
Fitting the model for MODE (16) ...
Predicting labels...
F1 score:  0.9743401011181902
              precision    recall  f1-score   support

       B-BLK      0.996     0.996     0.996      6658
       I-BLK      0.891     0.877     0.884        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.975     0.940     0.958        84
     B-FRAGP      0.710     0.613     0.658       124
     I-FRAGP      0.667     0.353     0.462        17
       B-JJP      0.959     0.915     0.936      3158
       I-JJP      0.826     0.683     0.748       278
      B-NEGP      0.826     0.935     0.877       107
      I-NEGP      0.828     0.960     0.889        25
        B-NP      0.963     0.972     0.968     40861
        I-NP      0.975     0.972     0.973     46950
 B-NULL__CCP      0.990     0.990     0.990       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.973     0.777     0.864        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.883     0.883     0.883       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.975     0.981     0.978       741
       I-RBP      0.969     0.969     0.969       191
       B-VGF      0.991     0.993     0.992      9911
       I-VGF      0.992     0.995     0.994      9273
      B-VGNF      0.948     0.963     0.956      1578
      I-VGNF      0.967     0.947     0.957       658
      B-VGNN      0.989     0.966     0.978      2511
      I-VGNN      0.990     0.991     0.990      3084

   micro avg      0.975     0.975     0.975    131574
   macro avg      0.741     0.703     0.716    131574
weighted avg      0.974     0.975     0.974    131574

Sentence Labelling Error :
Number of sentences wrongly labelled : 145
Fitting the model for MODE (24) ...
Predicting labels...
F1 score:  0.9752206188493475
              precision    recall  f1-score   support

       B-BLK      0.996     0.995     0.996      6658
       I-BLK      0.891     0.877     0.884        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.975     0.940     0.958        84
     B-FRAGP      0.675     0.621     0.647       124
     I-FRAGP      0.500     0.412     0.452        17
       B-JJP      0.963     0.916     0.939      3158
       I-JJP      0.833     0.719     0.772       278
      B-NEGP      0.826     0.935     0.877       107
      I-NEGP      0.828     0.960     0.889        25
        B-NP      0.963     0.972     0.968     40861
        I-NP      0.975     0.972     0.973     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.973     0.777     0.864        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.881     0.864     0.872       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.972     0.980     0.976       741
       I-RBP      0.974     0.969     0.971       191
       B-VGF      0.993     0.994     0.993      9911
       I-VGF      0.994     0.995     0.995      9273
      B-VGNF      0.966     0.967     0.966      1578
      I-VGNF      0.971     0.956     0.963       658
      B-VGNN      0.994     0.994     0.994      2511
      I-VGNN      0.992     0.997     0.994      3084

   micro avg      0.975     0.975     0.975    131574
   macro avg      0.736     0.708     0.717    131574
weighted avg      0.975     0.975     0.975    131574

Sentence Labelling Error :
Number of sentences wrongly labelled : 152