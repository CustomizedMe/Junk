Loading data...
# of sentences = 21086
Splitting data at 70%:30%...
Fitting the model for MODE (0) ...
Predicting labels...
F1 score:  0.9743319462389266
              precision    recall  f1-score   support

       B-BLK      0.996     0.996     0.996      6658
       I-BLK      0.906     0.892     0.899        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.988     0.940     0.963        84
     B-FRAGP      0.708     0.605     0.652       124
     I-FRAGP      0.625     0.294     0.400        17
       B-JJP      0.964     0.913     0.938      3158
       I-JJP      0.810     0.691     0.746       278
      B-NEGP      0.825     0.925     0.872       107
      I-NEGP      0.857     0.960     0.906        25
        B-NN      0.000     0.000     0.000         1
        B-NP      0.964     0.971     0.968     40860
        I-NP      0.973     0.973     0.973     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.973     0.766     0.857        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.882     0.877     0.879       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.976     0.980     0.978       741
       I-RBP      0.974     0.963     0.968       191
       B-VGF      0.990     0.993     0.991      9911
       I-VGF      0.991     0.995     0.993      9273
      B-VGNF      0.948     0.966     0.957      1578
      I-VGNF      0.960     0.953     0.957       658
      B-VGNN      0.992     0.967     0.979      2511
      I-VGNN      0.992     0.990     0.991      3084

   micro avg      0.975     0.975     0.975    131574
   macro avg      0.718     0.678     0.692    131574
weighted avg      0.974     0.975     0.974    131574

# of Errors = 3354
# of Sequence-level combinations with accuracy < 1.0 = 243
# of Sequence-level combinations with accuracy < 0.9 = 119
# of Sequence-level combinations with accuracy < 0.8 = 64
# of Sequence-level combinations with accuracy < 0.7 = 47
# of Sequence-level combinations with accuracy < 0.6 = 30
# of Sequence-level combinations with accuracy < 0.5 = 21
{'SYM-INJC': 0.0, 'UNK-SYM': 0.3333333333333333, 'NNP-NST': 0.18181818181818182, 'UNK-NNP': 0.0, 'SYM-VAUX': 0.0, 'VAUX-INJ': 0.0, 'RDP-QCC': 0.0, 'INJC-INJ': 0.0, 'RDP-NST': 0.0, 'WQ-NST': 0.0, 'NNP-QC': 0.3333333333333333, 'VM-UNK': 0.0, 'NEG-NEG': 0.0, 'QC-QCC': 0.0, 'SYM-JJC': 0.3333333333333333, 'INJC-INJC': 0.0, 'INJ-INJ': 0.0, 'UNK-NNPC': 0.0, 'QO-PRP': 0.0}

Fitting the model for MODE (1) ...
Predicting labels...
F1 score:  0.974209532811804
              precision    recall  f1-score   support

       B-BLK      0.996     0.996     0.996      6658
       I-BLK      0.894     0.908     0.901        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.988     0.940     0.963        84
     B-FRAGP      0.693     0.637     0.664       124
     I-FRAGP      0.500     0.353     0.414        17
       B-JJP      0.962     0.911     0.936      3158
       I-JJP      0.812     0.655     0.725       278
      B-NEGP      0.825     0.925     0.872       107
      I-NEGP      0.857     0.960     0.906        25
        B-NN      0.000     0.000     0.000         1
        B-NP      0.963     0.972     0.967     40860
        I-NP      0.974     0.972     0.973     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.973     0.777     0.864        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.878     0.890     0.884       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.975     0.981     0.978       741
       I-RBP      0.959     0.974     0.966       191
       B-VGF      0.991     0.993     0.992      9911
       I-VGF      0.992     0.994     0.993      9273
      B-VGNF      0.953     0.966     0.959      1578
      I-VGNF      0.962     0.951     0.956       658
      B-VGNN      0.987     0.970     0.979      2511
      I-VGNN      0.992     0.990     0.991      3084

   micro avg      0.974     0.974     0.974    131574
   macro avg      0.712     0.682     0.692    131574
weighted avg      0.974     0.974     0.974    131574

# of Errors = 3371
# of Sequence-level combinations with accuracy < 1.0 = 242
# of Sequence-level combinations with accuracy < 0.9 = 117
# of Sequence-level combinations with accuracy < 0.8 = 65
# of Sequence-level combinations with accuracy < 0.7 = 46
# of Sequence-level combinations with accuracy < 0.6 = 29
# of Sequence-level combinations with accuracy < 0.5 = 19
{'SYM-INJC': 0.0, 'UNK-SYM': 0.3333333333333333, 'NNP-NST': 0.18181818181818182, 'SYM-VAUX': 0.0, 'RDP-QCC': 0.0, 'INJC-INJ': 0.0, 'RDP-NST': 0.0, 'WQ-NST': 0.0, 'NNP-QC': 0.3333333333333333, 'NEG-NEG': 0.0, 'QC-QCC': 0.0, 'SYM-JJC': 0.3333333333333333, 'WQ-WQ': 0.3333333333333333, 'INJC-INJC': 0.0, 'NN-QFC': 0.0, 'INJ-INJ': 0.0, 'QO-PRP': 0.0}

Fitting the model for MODE (2) ...
Predicting labels...
F1 score:  0.9746951056358707
              precision    recall  f1-score   support

       B-BLK      0.996     0.996     0.996      6658
       I-BLK      0.892     0.892     0.892        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.975     0.940     0.958        84
     B-FRAGP      0.705     0.597     0.646       124
     I-FRAGP      0.538     0.412     0.467        17
       B-JJP      0.966     0.911     0.938      3158
       I-JJP      0.831     0.673     0.744       278
      B-NEGP      0.826     0.935     0.877       107
      I-NEGP      0.828     0.960     0.889        25
        B-NN      0.000     0.000     0.000         1
        B-NP      0.964     0.971     0.968     40860
        I-NP      0.973     0.973     0.973     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.973     0.777     0.864        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.883     0.883     0.883       154
 I-NULL__VGF      0.957     0.407     0.571        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.972     0.981     0.976       741
       I-RBP      0.959     0.974     0.966       191
       B-VGF      0.993     0.993     0.993      9911
       I-VGF      0.994     0.994     0.994      9273
      B-VGNF      0.952     0.968     0.960      1578
      I-VGNF      0.959     0.960     0.960       658
      B-VGNN      0.988     0.978     0.983      2511
      I-VGNN      0.990     0.994     0.992      3084

   micro avg      0.975     0.975     0.975    131574
   macro avg      0.713     0.683     0.693    131574
weighted avg      0.975     0.975     0.975    131574

# of Errors = 3306
# of Sequence-level combinations with accuracy < 1.0 = 241
# of Sequence-level combinations with accuracy < 0.9 = 118
# of Sequence-level combinations with accuracy < 0.8 = 63
# of Sequence-level combinations with accuracy < 0.7 = 46
# of Sequence-level combinations with accuracy < 0.6 = 28
# of Sequence-level combinations with accuracy < 0.5 = 20
{'SYM-INJC': 0.0, 'UNK-SYM': 0.3333333333333333, 'NNP-NST': 0.18181818181818182, 'UNK-NNP': 0.0, 'RDP-QCC': 0.0, 'INJC-INJ': 0.0, 'RDP-NST': 0.0, 'WQ-NST': 0.0, 'NNP-QC': 0.3333333333333333, 'NEG-NEG': 0.0, 'QC-QCC': 0.0, 'SYM-JJC': 0.3333333333333333, 'WQ-WQ': 0.3333333333333333, 'INJC-INJC': 0.0, 'NN-QFC': 0.0, 'INJ-INJ': 0.0, 'UNK-NNPC': 0.0, 'QO-PRP': 0.0}

Fitting the model for MODE (3) ...
Predicting labels...
F1 score:  0.9744745938032985
              precision    recall  f1-score   support

       B-BLK      0.996     0.996     0.996      6658
       I-BLK      0.879     0.892     0.885        65
       B-CCP      0.999     0.995     0.997      4789
       I-CCP      0.987     0.929     0.957        84
     B-FRAGP      0.718     0.597     0.652       124
     I-FRAGP      0.556     0.294     0.385        17
       B-JJP      0.967     0.909     0.937      3158
       I-JJP      0.824     0.673     0.741       278
      B-NEGP      0.826     0.935     0.877       107
      I-NEGP      0.857     0.960     0.906        25
        B-NN      0.000     0.000     0.000         1
        B-NP      0.964     0.971     0.967     40860
        I-NP      0.973     0.974     0.973     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.974     0.787     0.871        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.884     0.890     0.887       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.976     0.982     0.979       741
       I-RBP      0.959     0.974     0.966       191
       B-VGF      0.992     0.993     0.992      9911
       I-VGF      0.994     0.993     0.994      9273
      B-VGNF      0.952     0.966     0.959      1578
      I-VGNF      0.952     0.962     0.957       658
      B-VGNN      0.988     0.976     0.982      2511
      I-VGNN      0.989     0.994     0.991      3084

   micro avg      0.975     0.975     0.975    131574
   macro avg      0.715     0.679     0.691    131574
weighted avg      0.975     0.975     0.974    131574

# of Errors = 3334
# of Sequence-level combinations with accuracy < 1.0 = 241
# of Sequence-level combinations with accuracy < 0.9 = 118
# of Sequence-level combinations with accuracy < 0.8 = 60
# of Sequence-level combinations with accuracy < 0.7 = 45
# of Sequence-level combinations with accuracy < 0.6 = 27
# of Sequence-level combinations with accuracy < 0.5 = 18
{'SYM-INJC': 0.0, 'UNK-SYM': 0.3333333333333333, 'NNP-NST': 0.18181818181818182, 'RDP-QCC': 0.0, 'INJC-INJ': 0.0, 'RDP-NST': 0.0, 'WQ-NST': 0.0, 'NNP-QC': 0.3333333333333333, 'NEG-NEG': 0.0, 'QC-QCC': 0.0, 'SYM-JJC': 0.3333333333333333, 'INJC-INJC': 0.0, 'NN-QFC': 0.0, 'INJ-INJ': 0.0, 'UNK-NNPC': 0.0, 'QO-PRP': 0.0}

Fitting the model for MODE (8) ...
Predicting labels...
F1 score:  0.975352854818989
              precision    recall  f1-score   support

       B-BLK      0.996     0.995     0.996      6658
       I-BLK      0.894     0.908     0.901        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.988     0.940     0.963        84
     B-FRAGP      0.682     0.589     0.632       124
     I-FRAGP      0.600     0.353     0.444        17
       B-JJP      0.969     0.911     0.939      3158
       I-JJP      0.860     0.687     0.764       278
      B-NEGP      0.825     0.925     0.872       107
      I-NEGP      0.857     0.960     0.906        25
        B-NN      0.000     0.000     0.000         1
        B-NP      0.964     0.972     0.968     40860
        I-NP      0.974     0.974     0.974     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.974     0.787     0.871        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.874     0.857     0.866       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.973     0.981     0.977       741
       I-RBP      0.964     0.974     0.969       191
       B-VGF      0.994     0.993     0.993      9911
       I-VGF      0.995     0.995     0.995      9273
      B-VGNF      0.964     0.969     0.966      1578
      I-VGNF      0.966     0.953     0.959       658
      B-VGNN      0.994     0.994     0.994      2511
      I-VGNN      0.991     0.997     0.994      3084

   micro avg      0.976     0.976     0.976    131574
   macro avg      0.718     0.682     0.694    131574
weighted avg      0.975     0.976     0.975    131574

# of Errors = 3219
# of Sequence-level combinations with accuracy < 1.0 = 238
# of Sequence-level combinations with accuracy < 0.9 = 114
# of Sequence-level combinations with accuracy < 0.8 = 60
# of Sequence-level combinations with accuracy < 0.7 = 46
# of Sequence-level combinations with accuracy < 0.6 = 30
# of Sequence-level combinations with accuracy < 0.5 = 21
{'SYM-INJC': 0.0, 'UNK-SYM': 0.3333333333333333, 'NNP-NST': 0.18181818181818182, 'SYM-VAUX': 0.0, 'RDP-QCC': 0.0, 'INJC-INJ': 0.0, 'RDP-NST': 0.0, 'WQ-NST': 0.0, 'NNP-QC': 0.3333333333333333, 'VM-UNK': 0.0, 'NEG-NEG': 0.0, 'QC-QCC': 0.0, 'SYM-JJC': 0.3333333333333333, 'WQ-WQ': 0.3333333333333333, 'INJC-INJC': 0.0, 'VM-VMC': 0.0, 'INJ-INJ': 0.0, 'UNK-NNPC': 0.0, 'QO-PRP': 0.0}

Fitting the model for MODE (11) ...
Predicting labels...
F1 score:  0.9754029270950031
              precision    recall  f1-score   support

       B-BLK      0.996     0.995     0.996      6658
       I-BLK      0.879     0.892     0.885        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.975     0.940     0.958        84
     B-FRAGP      0.689     0.677     0.683       124
     I-FRAGP      0.500     0.471     0.485        17
       B-JJP      0.965     0.910     0.937      3158
       I-JJP      0.856     0.683     0.760       278
      B-NEGP      0.826     0.935     0.877       107
      I-NEGP      0.857     0.960     0.906        25
        B-NN      0.000     0.000     0.000         1
        B-NP      0.964     0.972     0.968     40860
        I-NP      0.974     0.973     0.974     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.974     0.787     0.871        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.872     0.883     0.877       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.976     0.980     0.978       741
       I-RBP      0.954     0.974     0.964       191
       B-VGF      0.994     0.993     0.993      9911
       I-VGF      0.995     0.994     0.994      9273
      B-VGNF      0.970     0.971     0.971      1578
      I-VGNF      0.962     0.964     0.963       658
      B-VGNN      0.992     0.996     0.994      2511
      I-VGNN      0.994     0.997     0.995      3084

   micro avg      0.976     0.976     0.976    131574
   macro avg      0.713     0.689     0.697    131574
weighted avg      0.975     0.976     0.975    131574

# of Errors = 3217
# of Sequence-level combinations with accuracy < 1.0 = 236
# of Sequence-level combinations with accuracy < 0.9 = 118
# of Sequence-level combinations with accuracy < 0.8 = 61
# of Sequence-level combinations with accuracy < 0.7 = 46
# of Sequence-level combinations with accuracy < 0.6 = 29
# of Sequence-level combinations with accuracy < 0.5 = 19
{'SYM-INJC': 0.0, 'NNP-NST': 0.18181818181818182, 'RDP-QCC': 0.0, 'INJC-INJ': 0.0, 'RDP-NST': 0.0, 'WQ-NST': 0.0, 'NNP-QC': 0.37037037037037035, 'NEG-NEG': 0.0, 'QC-QCC': 0.0, 'RB-UNK': 0.0, 'SYM-JJC': 0.3333333333333333, 'WQ-WQ': 0.3333333333333333, 'INJC-INJC': 0.0, 'VM-VMC': 0.0, 'INJ-INJ': 0.0, 'UNK-NNPC': 0.0, 'QO-PRP': 0.0}

Fitting the model for MODE (16) ...
Predicting labels...
F1 score:  0.9743288423863753
              precision    recall  f1-score   support

       B-BLK      0.996     0.996     0.996      6658
       I-BLK      0.891     0.877     0.884        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.975     0.940     0.958        84
     B-FRAGP      0.710     0.613     0.658       124
     I-FRAGP      0.667     0.353     0.462        17
       B-JJP      0.959     0.915     0.936      3158
       I-JJP      0.826     0.683     0.748       278
      B-NEGP      0.826     0.935     0.877       107
      I-NEGP      0.828     0.960     0.889        25
        B-NN      0.000     0.000     0.000         1
        B-NP      0.963     0.972     0.968     40860
        I-NP      0.975     0.972     0.973     46950
 B-NULL__CCP      0.990     0.990     0.990       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.973     0.777     0.864        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.883     0.883     0.883       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.975     0.981     0.978       741
       I-RBP      0.969     0.969     0.969       191
       B-VGF      0.991     0.993     0.992      9911
       I-VGF      0.992     0.995     0.994      9273
      B-VGNF      0.948     0.963     0.956      1578
      I-VGNF      0.967     0.947     0.957       658
      B-VGNN      0.989     0.966     0.978      2511
      I-VGNN      0.990     0.991     0.990      3084

   micro avg      0.975     0.975     0.975    131574
   macro avg      0.717     0.680     0.693    131574
weighted avg      0.974     0.975     0.974    131574

# of Errors = 3355
# of Sequence-level combinations with accuracy < 1.0 = 249
# of Sequence-level combinations with accuracy < 0.9 = 123
# of Sequence-level combinations with accuracy < 0.8 = 67
# of Sequence-level combinations with accuracy < 0.7 = 48
# of Sequence-level combinations with accuracy < 0.6 = 31
# of Sequence-level combinations with accuracy < 0.5 = 22
{'SYM-INJC': 0.0, 'UNK-SYM': 0.3333333333333333, 'NNP-NST': 0.18181818181818182, 'UNK-NNP': 0.0, 'SYM-VAUX': 0.0, 'WQ-NNC': 0.0, 'RDP-QCC': 0.0, 'INJC-INJ': 0.0, 'RDP-NST': 0.0, 'WQ-NST': 0.0, 'VM-RDP': 0.0, 'NNP-QC': 0.37037037037037035, 'NEG-NEG': 0.0, 'QC-QCC': 0.0, 'SYM-JJC': 0.3333333333333333, 'INJC-INJC': 0.0, 'NN-QFC': 0.0, 'INJ-INJ': 0.0, 'UNK-NNPC': 0.0, 'QO-PRP': 0.0}

Fitting the model for MODE (24) ...
Predicting labels...
F1 score:  0.9752093597423765
              precision    recall  f1-score   support

       B-BLK      0.996     0.995     0.996      6658
       I-BLK      0.891     0.877     0.884        65
       B-CCP      1.000     0.995     0.997      4789
       I-CCP      0.975     0.940     0.958        84
     B-FRAGP      0.675     0.621     0.647       124
     I-FRAGP      0.500     0.412     0.452        17
       B-JJP      0.963     0.916     0.939      3158
       I-JJP      0.833     0.719     0.772       278
      B-NEGP      0.826     0.935     0.877       107
      I-NEGP      0.828     0.960     0.889        25
        B-NN      0.000     0.000     0.000         1
        B-NP      0.963     0.972     0.968     40860
        I-NP      0.975     0.972     0.973     46950
 B-NULL__CCP      0.990     0.995     0.993       200
 B-NULL__JJP      0.000     0.000     0.000         0
  B-NULL__NP      0.973     0.777     0.864        94
  I-NULL__NP      0.000     0.000     0.000         1
 B-NULL__RBP      0.000     0.000     0.000         2
 B-NULL__VGF      0.881     0.864     0.872       154
 I-NULL__VGF      0.958     0.426     0.590        54
B-NULL__VGNF      0.000     0.000     0.000         3
I-NULL__VGNF      0.000     0.000     0.000         0
B-NULL__VGNN      0.000     0.000     0.000         3
       B-RBP      0.972     0.980     0.976       741
       I-RBP      0.974     0.969     0.971       191
       B-VGF      0.993     0.994     0.993      9911
       I-VGF      0.994     0.995     0.995      9273
      B-VGNF      0.966     0.967     0.966      1578
      I-VGNF      0.971     0.956     0.963       658
      B-VGNN      0.994     0.994     0.994      2511
      I-VGNN      0.992     0.997     0.994      3084

   micro avg      0.975     0.975     0.975    131574
   macro avg      0.712     0.685     0.694    131574
weighted avg      0.975     0.975     0.975    131574

# of Errors = 3243
# of Sequence-level combinations with accuracy < 1.0 = 246
# of Sequence-level combinations with accuracy < 0.9 = 119
# of Sequence-level combinations with accuracy < 0.8 = 64
# of Sequence-level combinations with accuracy < 0.7 = 48
# of Sequence-level combinations with accuracy < 0.6 = 31
# of Sequence-level combinations with accuracy < 0.5 = 22
{'SYM-INJC': 0.0, 'UNK-SYM': 0.3333333333333333, 'NNP-NST': 0.18181818181818182, 'UNK-NNP': 0.0, 'RDP-QCC': 0.0, 'INJC-INJ': 0.0, 'RDP-NST': 0.0, 'WQ-NST': 0.0, 'NST-INTF': 0.0, 'NNP-QC': 0.37037037037037035, 'VM-UNK': 0.0, 'NEG-NEG': 0.0, 'QC-QCC': 0.0, 'SYM-JJC': 0.3333333333333333, 'INJC-INJC': 0.0, 'NN-QFC': 0.0, 'VM-VMC': 0.0, 'INJ-INJ': 0.0, 'UNK-NNPC': 0.0, 'QO-PRP': 0.0}

